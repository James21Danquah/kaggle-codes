{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost best parameter | Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11504798, 12)\n",
      "(7669866, 12)\n",
      "(19174664, 12)\n",
      "CPU times: user 2.95 s, sys: 1.33 s, total: 4.28 s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading CSV files using pd\n",
    "train = pd.read_csv('/kaggle/input/playground-series-s4e7/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e7/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s4e7/sample_submission.csv')\n",
    "\n",
    "# Concatenating DataFrames using pd\n",
    "test['Response'] = 0\n",
    "full_df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# Printing shapes\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Previously_Insured_Annual_Premium']\n",
      "['Previously_Insured_Vehicle_Age']\n",
      "['Previously_Insured_Vehicle_Damage']\n",
      "['Previously_Insured_Vintage']\n"
     ]
    }
   ],
   "source": [
    "Categorical_feat1 = ['Previously_Insured']\n",
    "Categorical_feat2 = ['Annual_Premium','Vehicle_Age','Vehicle_Damage','Vintage']\n",
    "# features = [feat for feat in df.columns]\n",
    "\n",
    "#Feature_Feature Encoding\n",
    "for feat1 in Categorical_feat1:\n",
    "    for feat2 in Categorical_feat2:\n",
    "            full_df[feat1 + '_' + feat2] = full_df[feat1].astype(str) + '_' + full_df[feat2].astype(str)\n",
    "            print([feat1 + '_' + feat2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     int64\n",
       "Gender                                object\n",
       "Age                                    int64\n",
       "Driving_License                        int64\n",
       "Region_Code                          float64\n",
       "Previously_Insured                     int64\n",
       "Vehicle_Age                           object\n",
       "Vehicle_Damage                        object\n",
       "Annual_Premium                       float64\n",
       "Policy_Sales_Channel                 float64\n",
       "Vintage                                int64\n",
       "Response                               int64\n",
       "Previously_Insured_Annual_Premium     object\n",
       "Previously_Insured_Vehicle_Age        object\n",
       "Previously_Insured_Vehicle_Damage     object\n",
       "Previously_Insured_Vintage            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encode object columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for each in full_df.columns:\n",
    "    if full_df[each].dtype == 'object':\n",
    "        full_df[each] = le.fit_transform(full_df[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing float types to int32\n",
    "for each in full_df.columns:\n",
    "    if full_df[each].dtype == 'float64':\n",
    "        full_df[each] = full_df[each].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    int64\n",
       "Gender                                uint8\n",
       "Age                                   int64\n",
       "Driving_License                       int64\n",
       "Region_Code                           int64\n",
       "Previously_Insured                    int64\n",
       "Vehicle_Age                           uint8\n",
       "Vehicle_Damage                        uint8\n",
       "Annual_Premium                        int64\n",
       "Policy_Sales_Channel                  int64\n",
       "Vintage                               int64\n",
       "Response                              int64\n",
       "Previously_Insured_Annual_Premium    uint32\n",
       "Previously_Insured_Vehicle_Age        uint8\n",
       "Previously_Insured_Vehicle_Damage     uint8\n",
       "Previously_Insured_Vintage           uint16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop('id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11504798, 15)\n",
      "(7669866, 14)\n"
     ]
    }
   ],
   "source": [
    "train = full_df[:train.shape[0]] \n",
    "test = full_df[train.shape[0]:] \n",
    "test.drop('Response', axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "del full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "train['kfold'] = -1\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "y=train.Response.values\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "for k, (t_,v_) in enumerate(kf.split(x=train,y=y)):\n",
    "    train.loc[v_,'kfold']=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "preds = []\n",
    "aucs = []\n",
    "\n",
    "best_overall_auc = 0\n",
    "best_model_filename = 'best_catboost_model.joblib'\n",
    "\n",
    "def run(fold):\n",
    "    features = [c for c in train.columns if c not in ('Response', 'id', 'kfold')]\n",
    "    df_train = train[train['kfold']==fold].reset_index(drop=True)\n",
    "    df_valid = train[train['kfold']!=fold].reset_index(drop=True)\n",
    "\n",
    "    X_train = df_train[features].values\n",
    "    y_train = df_train['Response'].values\n",
    "    X_valid = df_valid[features].values\n",
    "    y_valid = df_valid['Response'].values\n",
    "    X_test = test[features].values\n",
    "\n",
    "    X_train_pool = Pool(X_train, y_train, cat_features=features.values)\n",
    "    X_valid_pool = Pool(X_valid, y_valid, cat_features=features.values)\n",
    "    X_test_pool =  Pool(X_test, cat_features=features.values)\n",
    "\n",
    "    params = {'learning_rate': uniform(0.01, 0.3),\n",
    "        'depth': randint(4, 10),\n",
    "        'l2_leaf_reg': uniform(1, 10),\n",
    "        'iterations': randint(1000, 5000)\n",
    "        }\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        early_stopping_rounds=200,\n",
    "        use_best_model=True,\n",
    "        eval_metric='AUC',\n",
    "        task_type='GPU',  # Use GPU for training\n",
    "        devices='all',  # Specify GPU device (if multiple GPUs are available)\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=100,\n",
    "        cv=3, verbose=1, n_jobs=-1, random_state=42, scoring='roc_auc')\n",
    "    \n",
    "    random_search.fit(X_train, y_train, cat_features=features)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    valid_preds = best_model.predict_proba(X_valid)[:,1]\n",
    "    auc = roc_auc_score(y_valid, valid_preds)\n",
    "    \n",
    "    print(f\"Fold {fold}, Best AUC: {random_search.best_score_}, AUC: {auc}\")\n",
    "    print(f\"Best parameters: {random_search.best_params_}\")\n",
    "    \n",
    "    if auc > best_overall_auc:\n",
    "        best_overall_auc = auc\n",
    "        joblib.dump(best_model, best_model_filename)\n",
    "        print(f\"New best model found and saved with AUC: {best_overall_auc}\")\n",
    "\n",
    "    preds.append(valid_preds)\n",
    "    aucs.append(auc)\n",
    "\n",
    "for fold in range(5):\n",
    "    run(fold_)\n",
    "\n",
    "print(f\"\\nOverall AUC: {np.mean(aucs):.5f} +/- {np.std(aucs):.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"________________________________OPTIMIZATION____________________________\")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "preds = []\n",
    "aucs = []\n",
    "\n",
    "best_overall_auc = 0\n",
    "best_model_filename = 'best_catboost_model.joblib'\n",
    "\n",
    "# Load the best model from the previous optimization\n",
    "best_model = joblib.load('previous_best_catboost_model.joblib')\n",
    "\n",
    "# Prepare the test data once\n",
    "features = [c for c in train.columns if c not in ('Response', 'id', 'kfold')]\n",
    "X_test = test[features].values\n",
    "X_test_pool = Pool(X_test, cat_features=features)\n",
    "\n",
    "def run(fold):\n",
    "    global best_overall_auc\n",
    "    df_train = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    df_valid = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    X_train = df_train[features].values\n",
    "    y_train = df_train['Response'].values\n",
    "    X_valid = df_valid[features].values\n",
    "    y_valid = df_valid['Response'].values\n",
    "\n",
    "    X_train_pool = Pool(X_train, y_train, cat_features=features)\n",
    "    X_valid_pool = Pool(X_valid, y_valid, cat_features=features)\n",
    "\n",
    "    # Create a new model with the same parameters as the best model\n",
    "    model = CatBoostClassifier(\n",
    "        **best_model.get_params(),\n",
    "        iterations=5000,  # Set to 5000 iterations\n",
    "        early_stopping_rounds=200,\n",
    "        use_best_model=True,\n",
    "        eval_metric='AUC',\n",
    "        task_type='GPU',\n",
    "        devices='0:1',  # Use both GPUs. Adjust if needed.\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_pool, eval_set=X_valid_pool)\n",
    "\n",
    "    valid_preds = model.predict_proba(X_valid_pool)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, valid_preds)\n",
    "    \n",
    "    print(f\"Fold {fold}, AUC: {auc:.5f}\")\n",
    "    \n",
    "    if auc > best_overall_auc:\n",
    "        best_overall_auc = auc\n",
    "        joblib.dump(model, best_model_filename)\n",
    "        print(f\"New best model found and saved with AUC: {best_overall_auc:.5f}\")\n",
    "\n",
    "    aucs.append(auc)\n",
    "\n",
    "for fold in range(5):\n",
    "    run(fold)\n",
    "\n",
    "print(f\"\\nOverall AUC: {np.mean(aucs):.5f} +/- {np.std(aucs):.5f}\")\n",
    "\n",
    "# Load the best model from this round of optimization\n",
    "best_model = joblib.load(best_model_filename)\n",
    "\n",
    "# Make predictions on the entire test set using the best model\n",
    "final_preds = best_model.predict_proba(X_test_pool)[:, 1]\n",
    "\n",
    "# You can now use final_preds for your submission or further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Response'] = final_preds\n",
    "sample_submission.to_csv('ROR-Final_Submission.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
